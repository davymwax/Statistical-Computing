---
title: "Homework 4"
author: "David Mwakima"
date: "02/21/2023"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{homework4}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  rmarkdown.html_vignette.check_title = FALSE
)
```

## Question 1 (Part (a))

In this part I added to my package a function that can fit logistic regression to data using two optimization methods:

\begin{itemize}
\item Newton-Raphson/Fisher scoring/IRLS method
\item Gradient descent/steepest ascent method
\end{itemize}

The function, `logistic_MLE()`, has its [source code](https://github.com/miningroup/your-stat-230-r-package-davymwax) here and the [documentation](https://github.com/miningroup/your-stat-230-r-package-davymwax) here. It returns:

\begin{itemize}
\item[i.] MLEs of regression coefficients,
\item[ii.] their corresponding asymptotic confidence intervals,
\item[iii.] and a vector of the log-likelihoods "visited" by the chosen optimization option
\end{itemize}

```{r "loading the function", include=FALSE}
library(temp)
library(kableExtra)
source("/Users/dmwakima/Documents/09_R/07_Winter_23/STATS230/firstpkg/R/logistic_MLE.R")
```

## Question 1 (Part (b))

Here I apply my function to the heart-disease data taken from a larger dataset, described in  Rousseauw et al, 1983, South African Medical Journal. It consists of a retrospective sample of males in a heart-disease high-risk region of the Western Cape, South Africa.

```{r "loading the data", include=FALSE}
mydata <- read.csv("/Users/dmwakima/Documents/09_R/07_Winter_23/STATS230/firstpkg/data/SAheart.csv")
```

```{r "comparing", echo=FALSE}
Y <- as.numeric(mydata[, c("chd")])
n <- length(Y)
X <- subset(mydata, select = -c(row.names,chd))
X$famhist <- factor(X$famhist)
X$famhist <- as.numeric(X$famhist)
X$famhist[X$famhist == 1] <- 0
X$famhist[X$famhist == 2] <- 1
X <- as.matrix(X)
p <- dim(X)[2]
init <- c(rep(0, p + 1))
iter <- 200
newton_raphson <- logistic_MLE(Y, X, init, iter, method=1)
gradient_desc <- logistic_MLE(Y, X, init, iter, method=2)
model <- glm(chd~sbp+tobacco+ldl+adiposity+famhist+typea+obesity+alcohol+age,family = binomial(link="logit"), data=mydata)
```

## Question 1 (Part(c))

Here I compare the convergence of the two optimization options by plotting iterations vs. log-likelihood values of the two optimization algorithms.

```{r "comparing convergence", fig.width=7, fig.height=6, echo=FALSE}
plot(x=seq(1:5), 
     y=newton_raphson$`Log-Likelihood Values`,
     type = "l",
     xlim = c(1,130),
     ylab = "Log-Likelihood Values",
     xlab = "Steps in Iteration",
     col = "red")
lines(x=seq(1:130), 
      y=gradient_desc$`Log-Likelihood Values`,
      col= "blue")
legend(x="bottomright", c("Newton-Raphson", "Gradient Descent"), lty = 1, col = c("red", "blue"))
```

Here I benchmark the runtimes of the two optimization algorithms.

```{r "microbenchmarking", include=FALSE}
set.seed(23758)
library(bench)
NR_results <- as.data.frame(bench::mark(logistic_MLE(Y, X, init, iter, method=1)))
GD_results <- as.data.frame(bench::mark(logistic_MLE(Y, X, init, iter, method=1)))
results <- rbind(NR_results, GD_results)
rownames(results) <- c("Newton-Raphson Algorithm", "Gradient Descent Algorithm")
```

```{r "tab2", echo=FALSE}
results <- results[, c(2, 3)]
results %>%
  kable(format = "html",
        align = "c",
        digits = 4,
        caption = "Results of Microbenchmarking",
        booktabs = TRUE)
```

